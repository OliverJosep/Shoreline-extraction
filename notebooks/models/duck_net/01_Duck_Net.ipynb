{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Add the src directory to the path. TEMPORARY FIX\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), \"../../..\")))\n",
    "\n",
    "from models.duck_net.duck_net import DuckNet\n",
    "from src.models.data_management.cnn_formes import CNNFormes\n",
    "from src.data_processing.dataset_loader import CoastData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duck1\n",
      "x torch.Size([4, 3, 352, 352])\n",
      "duck_down torch.Size([4, 17, 352, 352])\n",
      "conv_duck torch.Size([4, 34, 176, 176])\n",
      "torch.Size([4, 3, 352, 352])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "model = DuckNet(num_classes=3)\n",
    "dummy = torch.randn(4, 3, 352, 352)\n",
    "out = model.model(dummy)\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CoastData: arenaldentem - 40 images\n",
      "Coast: arenaldentem, Total size: 40\n"
     ]
    }
   ],
   "source": [
    "# Load the data to split it and save it to a dict\n",
    "path = os.path.abspath(os.path.join(os.getcwd(), \"../../../data/processed/\"))\n",
    "data = CoastData(data_path=path, name=\"arenaldentem\")\n",
    "\n",
    "data_split = data.split_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "unet = DuckNet(num_classes=3, experiment_name=\"test_experiments\", use_mlflow=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data to the model\n",
    "data = unet.load_data(data_split, CNNFormes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating folders for the artifacts at /Users/josep/Documents/SOCIB/Shoreline-extraction/artifacts/2025-02-27-09-24-54\n",
      "Epoch 1/1\n",
      "Duck1\n",
      "x torch.Size([16, 3, 256, 256])\n",
      "duck_down torch.Size([16, 17, 256, 256])\n",
      "conv_duck torch.Size([16, 34, 128, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/visio/lib/python3.9/site-packages/torcheval/metrics/functional/classification/accuracy.py:275: UserWarning: The reduce argument of torch.scatter with Tensor src is deprecated and will be removed in a future PyTorch release. Use torch.scatter_reduce instead for more reduction options. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/native/TensorAdvancedIndexing.cpp:234.)\n",
      "  num_correct = mask.new_zeros(num_classes).scatter_(0, target, mask, reduce=\"add\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duck1\n",
      "x torch.Size([12, 3, 256, 256])\n",
      "duck_down torch.Size([12, 17, 256, 256])\n",
      "conv_duck torch.Size([12, 34, 128, 128])\n",
      "train metrics: \n",
      "\ttrain_loss: 1.0291645228862762\n",
      "\ttrain_accuracy: 0.48927316069602966\n",
      "\ttrain_f1_score: 0.44978201389312744\n",
      "\ttrain_precision: 0.45572519302368164\n",
      "\ttrain_recall: 0.48927316069602966\n",
      "\ttrain_confusion_matrix: tensor([[149128., 106900.,  19444.],\n",
      "        [297576., 593921., 255689.],\n",
      "        [129176., 114628., 168546.]])\n",
      "\n",
      "Duck1\n",
      "x torch.Size([8, 3, 256, 256])\n",
      "duck_down torch.Size([8, 17, 256, 256])\n",
      "conv_duck torch.Size([8, 34, 128, 128])\n",
      "validation metrics: \n",
      "\tvalidation_loss: 1.3972357511520386\n",
      "\tvalidation_accuracy: 0.3333333432674408\n",
      "\tvalidation_f1_score: 0.08907058835029602\n",
      "\tvalidation_precision: 0.051403045654296875\n",
      "\tvalidation_recall: 0.3333333432674408\n",
      "\tvalidation_confusion_matrix: tensor([[ 80850.,      0.,      0.],\n",
      "        [331149.,      0.,      0.],\n",
      "        [112289.,      0.,      0.]])\n",
      "\n",
      "Validation loss improved from inf to 1.397236. Saving the model. Early stopping counter: 0/25\n"
     ]
    }
   ],
   "source": [
    "artifact_path = os.path.abspath(os.path.join(path, \"../../artifacts/\"))\n",
    "\n",
    "description = \"\"\n",
    "\n",
    "# Train the model\n",
    "unet.train(epochs=1, artifact_path=artifact_path, run_description=description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "visio",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
