{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# Add the src directory to the path. TEMPORARY FIX\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), \"../../..\")))\n",
    "\n",
    "from models.unet.unet import UNet\n",
    "from src.models.data_management.cnn_formes import CNNFormes\n",
    "from src.data_processing.dataset_loader import CoastData\n",
    "from src.models.data_management.data_loader import DataLoaderManager\n",
    "\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data to split it and save it to a dict\n",
    "path = os.path.abspath(os.path.join(os.getcwd(), \"../../../data/patchify_4_classes/\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unet = UNet(num_classes=4, experiment_name=\"test_experiments\", use_mlflow=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data to the model\n",
    "data = unet.load_data(path, CNNFormes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not classified percentage: 42.260%\n",
    "\n",
    "Land percentage: 31.173%\n",
    "\n",
    "Sea percentage: 26.415%\n",
    "\n",
    "Shoreline percentage: 0.153%\n",
    "\n",
    "---\n",
    "\n",
    "not_classified = 42,260 / 42,260 =  1\n",
    "\n",
    "land = 42,260 / 31,173 = 1,36\n",
    "\n",
    "sea = 142,260 / 26,415 = 1,60\n",
    "\n",
    "shoreline = 42,260 / 0,153 = 276,14\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight = [1, 1.36, 1.60, 276.14]\n",
    "\n",
    "artifact_path = os.path.abspath(os.path.join(path, \"../../../artifacts/\"))\n",
    "\n",
    "# Train the model\n",
    "# unet.train(epochs=50, loss_function_name=\"BCEWithLogitsLoss\", weight=weight, artifact_path=artifact_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict one patch\n",
    "artifact_path = os.path.abspath(os.path.join(os.getcwd(), \"../../../artifacts/\"))\n",
    "data_path = os.path.abspath(os.path.join(os.getcwd(), \"../../../data/patchify_4_classes/\"))\n",
    "\n",
    "data = DataLoaderManager.load_data(data_path)\n",
    "index = 0 # 72\n",
    "img_path = data[\"test\"]['images'][index]\n",
    "img_path = \"/srv/Shoreline-extraction/data/patchify_4_classes/test/images/1525622460.Sun.May.06_17_01_00.CET.2018.cies.image.patch.0_1.jpg\"\n",
    "mask_path = data[\"test\"]['masks'][index]\n",
    "mask_path = \"/srv/Shoreline-extraction/data/patchify_4_classes/test/masks/1525622460.Sun.May.06_17_01_00.CET.2018.cies.mask.patch.0_1.png\"\n",
    "print(img_path)\n",
    "print(mask_path)\n",
    "\n",
    "unet.load_model(os.path.abspath(os.path.join(artifact_path, \"2025-02-19-15-28-50/models/best_model.pth\")))\n",
    "\n",
    "img = cv2.imread(img_path)\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "# pred = unet.predict(img)\n",
    "pred = unet.predict(img_path)\n",
    "\n",
    "print(np.unique(mask, return_counts=True))\n",
    "print(np.unique(pred.cpu(), return_counts=True))\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(1, 3, figsize=(15, 5))\n",
    "fig.suptitle(f\"Img path: {img_path.split('/')[-1]}\", y=0.05)\n",
    "\n",
    "ax[0].imshow(img)\n",
    "ax[0].set_title(\"Image\")\n",
    "\n",
    "ax[1].imshow(mask)\n",
    "ax[1].set_title(\"Mask\")\n",
    "\n",
    "ax[2].imshow(pred.cpu().squeeze())\n",
    "ax[2].set_title(\"Prediction\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the full image\n",
    "artifact_path = os.path.abspath(os.path.join(os.getcwd(), \"../../../artifacts/\"))\n",
    "data_path = os.path.abspath(os.path.join(os.getcwd(), \"../../../data/processed_4_classes/\"))\n",
    "\n",
    "coast_data = CoastData(data_path)\n",
    "split = coast_data.split_data()\n",
    "\n",
    "data = DataLoaderManager.load_data(split)\n",
    "index = 1 # 25 # 72\n",
    "img_path = data[\"test\"]['images'][index]\n",
    "#img_path = \"/srv/Shoreline-extraction/data/processed_4_classes/images/1525622460.Sun.May.06_17_01_00.CET.2018.cies.image.jpg\"\n",
    "print(img_path)\n",
    "mask_path = data[\"test\"]['masks'][index]\n",
    "print(mask_path)\n",
    "#mask_path = \"/srv/Shoreline-extraction/data/processed_4_classes/masks/1525622460.Sun.May.06_17_01_00.CET.2018.cies.mask.png\"\n",
    "\n",
    "img = cv2.imread(img_path)\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "unet.load_model(os.path.abspath(os.path.join(artifact_path, \"2025-02-19-15-28-50/models/best_model.pth\")))\n",
    "\n",
    "pred = unet.predict_patch(img_path, combination=\"max\")\n",
    "\n",
    "print(np.unique(mask, return_counts=True))\n",
    "print(np.unique(pred, return_counts=True))\n",
    "\n",
    "fig, ax = plt.subplots(1, 3, figsize=(15, 4))\n",
    "fig.suptitle(f\"Img path: {img_path.split('/')[-1]}\", y=0.05)\n",
    "\n",
    "ax[0].imshow(img)\n",
    "ax[0].set_title(\"Image\")\n",
    "\n",
    "ax[1].imshow(mask)\n",
    "ax[1].set_title(\"Mask\")\n",
    "\n",
    "ax[2].imshow(pred.squeeze())\n",
    "ax[2].set_title(\"Prediction\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the full image\n",
    "artifact_path = os.path.abspath(os.path.join(os.getcwd(), \"../../../artifacts/\"))\n",
    "data_path = os.path.abspath(os.path.join(os.getcwd(), \"../../../data/processed_4_classes/\"))\n",
    "\n",
    "coast_data = CoastData(data_path)\n",
    "split = coast_data.split_data()\n",
    "\n",
    "data = DataLoaderManager.load_data(split)\n",
    "index = 100 # 25 # 72\n",
    "img_path = data[\"test\"]['images'][index]\n",
    "mask_path = data[\"test\"]['masks'][index]\n",
    "\n",
    "img = cv2.imread(img_path)\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "unet.load_model(os.path.abspath(os.path.join(artifact_path, \"2025-02-19-15-28-50/models/best_model.pth\")))\n",
    "\n",
    "pred = unet.predict_patch(img_path, combination=\"max\")\n",
    "\n",
    "print(np.unique(mask, return_counts=True))\n",
    "print(np.unique(pred, return_counts=True))\n",
    "\n",
    "fig, ax = plt.subplots(1, 3, figsize=(15, 4))\n",
    "fig.suptitle(f\"Img path: {img_path.split('/')[-1]}\", y=0.05)\n",
    "\n",
    "ax[0].imshow(img)\n",
    "ax[0].set_title(\"Image\")\n",
    "\n",
    "ax[1].imshow(mask)\n",
    "ax[1].set_title(\"Mask\")\n",
    "\n",
    "ax[2].imshow(pred.squeeze())\n",
    "ax[2].set_title(\"Prediction\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models.metrics import Metrics\n",
    "\n",
    "artifact_path = os.path.abspath(os.path.join(os.getcwd(), \"../../../artifacts/\"))\n",
    "\n",
    "average = None\n",
    "num_classes = 4\n",
    "metrics = {\n",
    "    \"train\": Metrics(phase=\"train\", num_classes=num_classes, average=average, compute_loss=False),\n",
    "    \"validation\": Metrics(phase=\"val\", num_classes=num_classes, average=average, compute_loss=False),\n",
    "    \"test\": Metrics(phase=\"test\", num_classes=num_classes, average=average, compute_loss=False)\n",
    "}\n",
    "\n",
    "# Load the data to split it and save it to a dict\n",
    "unet = UNet(num_classes=num_classes, experiment_name=\"test_experiments\", use_mlflow=False)\n",
    "unet.load_model(os.path.abspath(os.path.join(artifact_path, \"2025-02-19-15-28-50/models/best_model.pth\")))\n",
    "\n",
    "data_path = os.path.abspath(os.path.join(os.getcwd(), \"../../../data/processed_4_classes/\"))\n",
    "\n",
    "coast_data = CoastData(data_path)\n",
    "split = coast_data.split_data()\n",
    "\n",
    "data = DataLoaderManager.load_data(split)\n",
    "\n",
    "for split in data:\n",
    "    split = \"test\"\n",
    "    print(f\"Split: {split}\")\n",
    "    print(f\"Number of images: {len(data[split]['images'])}\")\n",
    "    for img_path, mask_path in zip(data[split][\"images\"], data[split][\"masks\"]):\n",
    "        # print(img_path)\n",
    "        pred = unet.predict_patch(img_path, combination=\"max\")\n",
    "        mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
    "        mask = torch.from_numpy(mask).float() \n",
    "        metrics[split].update_metrics(mask, pred)\n",
    "\n",
    "    metrics[split].compute()\n",
    "    print(metrics[split].get_last_epoch_info())\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics with margin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models.metrics import Metrics\n",
    "\n",
    "artifact_path = os.path.abspath(os.path.join(os.getcwd(), \"../../../artifacts/\"))\n",
    "\n",
    "num_classes = 4\n",
    "margin = 10\n",
    "metrics = {\n",
    "    \"train\": Metrics(phase=\"train\", num_classes=num_classes, average=None, use_margin=True, margin = margin),\n",
    "    \"validation\": Metrics(phase=\"val\", num_classes=num_classes, average=None, use_margin=True, margin = margin),\n",
    "    \"test\": Metrics(phase=\"test\", num_classes=num_classes, average=None, use_margin=True, margin = margin)\n",
    "}\n",
    "\n",
    "# Load the data to split it and save it to a dict\n",
    "unet = UNet(num_classes=num_classes, experiment_name=\"test_experiments\", use_mlflow=False)\n",
    "unet.load_model(os.path.abspath(os.path.join(artifact_path, \"2025-02-19-15-28-50/models/best_model.pth\")))\n",
    "\n",
    "data_path = os.path.abspath(os.path.join(os.getcwd(), \"../../../data/processed_4_classes/\"))\n",
    "\n",
    "coast_data = CoastData(data_path)\n",
    "split = coast_data.split_data()\n",
    "\n",
    "data = DataLoaderManager.load_data(split)\n",
    "\n",
    "for split in data:\n",
    "    print(f\"Split: {split}\")\n",
    "    for img_path, mask_path in zip(data[split][\"images\"], data[split][\"masks\"]):\n",
    "        print(img_path)\n",
    "        pred = unet.predict_patch(img_path, combination=\"max\")\n",
    "        mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
    "        mask = torch.from_numpy(mask).float() \n",
    "        metrics[split].update_metrics(pred, mask)\n",
    "        break\n",
    "\n",
    "    metrics[split].compute()\n",
    "    print(metrics[split].get_last_epoch_info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models.metrics import Metrics\n",
    "\n",
    "artifact_path = os.path.abspath(os.path.join(os.getcwd(), \"../../../artifacts/\"))\n",
    "\n",
    "num_classes = 4\n",
    "margin = 10\n",
    "metrics = {\n",
    "    \"train\": Metrics(phase=\"train\", num_classes=num_classes, average=None, use_margin=True, margin = margin),\n",
    "    \"validation\": Metrics(phase=\"val\", num_classes=num_classes, average=None, use_margin=True, margin = margin),\n",
    "    \"test\": Metrics(phase=\"test\", num_classes=num_classes, average=None, use_margin=True, margin = margin)\n",
    "}\n",
    "\n",
    "# Load the data to split it and save it to a dict\n",
    "unet = UNet(num_classes=num_classes, experiment_name=\"test_experiments\", use_mlflow=False)\n",
    "unet.load_model(os.path.abspath(os.path.join(artifact_path, \"2025-02-19-15-28-50/models/best_model.pth\")))\n",
    "\n",
    "data_path = os.path.abspath(os.path.join(os.getcwd(), \"../../../data/processed_4_classes/\"))\n",
    "\n",
    "coast_data = CoastData(data_path)\n",
    "split = coast_data.split_data()\n",
    "\n",
    "data = DataLoaderManager.load_data(split)\n",
    "\n",
    "for split in data:\n",
    "    print(f\"Split: {split}\")\n",
    "    if (split == \"train\" or split == \"validation\"):\n",
    "        continue\n",
    "    for img_path, mask_path in zip(data[split][\"images\"], data[split][\"masks\"]):\n",
    "        pred = unet.predict_patch(img_path, combination=\"max\")\n",
    "        mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
    "        mask = torch.from_numpy(mask).float() \n",
    "        metrics[split].update_metrics(pred, mask)\n",
    "\n",
    "    metrics[split].compute()\n",
    "    print(metrics[split].get_last_epoch_info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the results to an output folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a folders system to save the results\n",
    "# SCLabels_prediction_by_set_unet\n",
    "#   - images\n",
    "#       - train\n",
    "#       - validation\n",
    "#       - test\n",
    "#   - masks\n",
    "#       - train\n",
    "#       - validation\n",
    "#       - test\n",
    "#   - predicted_mask\n",
    "#       - train\n",
    "#       - validation\n",
    "#       - test\n",
    "\n",
    "# Create the folders\n",
    "subfolders = [\"images\", \"masks\", \"predicted_mask\"]\n",
    "subset = [\"train\", \"validation\", \"test\"]\n",
    "\n",
    "path = os.path.abspath(os.path.join(os.getcwd(), \"../../../data/SCLabels_prediction_by_set_unet_4_classes\"))\n",
    "\n",
    "os.makedirs(path, exist_ok=True)\n",
    "for subfolder in subfolders:\n",
    "    for s in subset:\n",
    "        os.makedirs(os.path.join(path, subfolder, s), exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for split in data:\n",
    "    print(f\"Split: {split}\")\n",
    "    for img_path, mask_path in zip(data[split][\"images\"], data[split][\"masks\"]):\n",
    "        pred = unet.predict_patch(img_path, combination=\"max\")\n",
    "        mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
    "        \n",
    "        # Save the images\n",
    "        img = cv2.imread(img_path)\n",
    "        img_name = os.path.basename(img_path)\n",
    "        mask_name = os.path.basename(mask_path)\n",
    "\n",
    "        cv2.imwrite(os.path.join(path, \"images\", split, img_name), img)\n",
    "        cv2.imwrite(os.path.join(path, \"masks\", split, mask_name), mask)\n",
    "        cv2.imwrite(os.path.join(path, \"predicted_mask\", split, mask_name), pred.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "imagine",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
