{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/albumentations/__init__.py:28: UserWarning: A new version of Albumentations is available: '2.0.5' (you have '2.0.4'). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n",
      "  check_for_updates()\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "# Add the src directory to the path. TEMPORARY FIX\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), \"../../..\")))\n",
    "\n",
    "from models.attention_unet.attention_unet import Attention_UNet\n",
    "from src.models.data_management.cnn_formes import CNNFormes\n",
    "from src.data_processing.dataset_loader import CoastData\n",
    "from src.models.metrics import Metrics\n",
    "\n",
    "from src.models.data_management.data_loader import DataLoaderManager\n",
    "\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CoastData: global - 1717 images\n",
      "Coast: agrelo, Total size: 244\n",
      "Coast: arenaldentem, Total size: 40\n",
      "Coast: cadiz, Total size: 946\n",
      "Coast: cies, Total size: 430\n",
      "Coast: samarador, Total size: 57\n"
     ]
    }
   ],
   "source": [
    "artifact_path = os.path.abspath(os.path.join(os.getcwd(), \"../../../artifacts/\"))\n",
    "\n",
    "num_classes = 3\n",
    "metrics = {\n",
    "    \"train\": Metrics(phase=\"train\", num_classes=num_classes, average=None, use_margin=False),\n",
    "    \"validation\": Metrics(phase=\"val\", num_classes=num_classes, average=None, use_margin=False),\n",
    "    \"test\": Metrics(phase=\"test\", num_classes=num_classes, average=None, use_margin=False) # 'macro'\n",
    "}\n",
    "\n",
    "# Load the data to split it and save it to a dict\n",
    "model = Attention_UNet(num_classes=3, experiment_name=\"test_experiments\", use_mlflow=False)\n",
    "\n",
    "model.load_model(os.path.abspath(os.path.join(artifact_path, \"2025-03-06-22-30-23/models/best_model.pth\")))\n",
    "\n",
    "data_path = os.path.abspath(os.path.join(os.getcwd(), \"../../../data/processed\"))\n",
    "\n",
    "coast_data = CoastData(data_path)\n",
    "split = coast_data.split_data()\n",
    "\n",
    "data = DataLoaderManager.load_data(split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split: train\n",
      "train metrics: \n",
      "\ttrain_accuracy: tensor([0.9984, 0.9891, 0.9922])\n",
      "\ttrain_f1_score: tensor([0.9987, 0.9906, 0.9904])\n",
      "\ttrain_precision: tensor([0.9989, 0.9921, 0.9887])\n",
      "\ttrain_recall: tensor([0.9984, 0.9891, 0.9922])\n",
      "\ttrain_confusion_matrix: \n",
      "\t\t0.9984 0.0009 0.0007\n",
      "\t\t0.0004 0.9891 0.0105\n",
      "\t\t0.0004 0.0074 0.9922\n",
      "\n",
      "Split: validation\n",
      "val metrics: \n",
      "\tval_accuracy: tensor([0.9987, 0.9821, 0.9830])\n",
      "\tval_f1_score: tensor([0.9988, 0.9826, 0.9825])\n",
      "\tval_precision: tensor([0.9989, 0.9830, 0.9819])\n",
      "\tval_recall: tensor([0.9987, 0.9821, 0.9830])\n",
      "\tval_confusion_matrix: \n",
      "\t\t0.9987 0.0008 0.0005\n",
      "\t\t0.0006 0.9821 0.0174\n",
      "\t\t0.0003 0.0167 0.9830\n",
      "\n",
      "Split: test\n",
      "test metrics: \n",
      "\ttest_accuracy: tensor([0.9987, 0.9807, 0.9729])\n",
      "\ttest_f1_score: tensor([0.9987, 0.9773, 0.9764])\n",
      "\ttest_precision: tensor([0.9986, 0.9739, 0.9800])\n",
      "\ttest_recall: tensor([0.9987, 0.9807, 0.9729])\n",
      "\ttest_confusion_matrix: \n",
      "\t\t0.9987 0.0009 0.0005\n",
      "\t\t0.0004 0.9807 0.0190\n",
      "\t\t0.0006 0.0264 0.9729\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for split in data:\n",
    "    print(f\"Split: {split}\")\n",
    "    for img_path, mask_path in zip(data[split][\"images\"], data[split][\"masks\"]):\n",
    "        pred = model.predict_patch(img_path, combination=\"max\")\n",
    "        mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
    "        mask = torch.from_numpy(mask).float() \n",
    "        metrics[split].update_metrics(pred, mask)\n",
    "\n",
    "    metrics[split].compute()\n",
    "    print(metrics[split].get_last_epoch_info())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
